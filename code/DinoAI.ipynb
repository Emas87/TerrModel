{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install mss pydirectinput pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "#import gymnasium as gym\n",
    "#from gymnasium import spaces\n",
    "import gym\n",
    "from gym import spaces\n",
    "from TerrarianEyes import TerrarianEyes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "class TerrEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Setup spaces\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                'map' :       spaces.Box(low=0, high=11, shape=(67, 120), dtype=np.int8),\n",
    "                'inventory' : spaces.Box(low=0, high=11, shape=(9,10), dtype=np.int8),\n",
    "            }\n",
    "        )\n",
    "        self.action_space = spaces.Discrete(7)\n",
    "        # Capture game frames\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top': 0, 'left': 0, 'width': 1920, 'height': 1080}\n",
    "        self.done_location = {'top': 460, 'left': 760, 'width': 400, 'height': 70}\n",
    "        self.action_map = {\n",
    "            0: 'no_op',\n",
    "            1: 'space',\n",
    "            2: 'd', \n",
    "            3: 'a', \n",
    "            4: 'attack',\n",
    "            5: 'cut'\n",
    "        }\n",
    "        # Create Instance\n",
    "        tiles_weights_path = os.path.join('runs', 'train', 'yolov5s6-tiles', 'weights', 'best.pt')\n",
    "        objects_weights_path = os.path.join('runs', 'train', 'yolov5l6-objects', 'weights', 'best.pt')\n",
    "        self.eyes = TerrarianEyes(tiles_weights_path, objects_weights_path)\n",
    "        self.timer = None\n",
    "        self.time_limit = 360\n",
    "        self.day_timer = time.time()\n",
    "        self.day_limit = 300\n",
    "           \n",
    "    def step(self, action):\n",
    "        if self.timer is None:\n",
    "            raise AssertionError(\"Cannot call env.step() before calling reset()\")\n",
    "        # Get current health\n",
    "        health = self.eyes.map.getHealth()\n",
    "        reward = 0\n",
    "        if action == 1:\n",
    "            # press 'action' key and hold it down\n",
    "            pydirectinput.keyDown(self.action_map[action])\n",
    "\n",
    "            # keep the key pressed for 2 seconds\n",
    "            time.sleep(0.3)\n",
    "            # release the 'action' key\n",
    "            pydirectinput.keyUp(self.action_map[action])\n",
    "        elif action < 4:\n",
    "            # press 'action' key and hold it down\n",
    "            pydirectinput.keyDown(self.action_map[action])\n",
    "\n",
    "            # keep the key pressed for 2 seconds\n",
    "            time.sleep(0.3)\n",
    "            # release the 'action' key\n",
    "            pydirectinput.keyUp(self.action_map[action])\n",
    "            reward = 1 \n",
    "        else: \n",
    "            # In case we need map or inventory\n",
    "            if action == 4: # attack\n",
    "                # find closest enemy position and check \n",
    "                #with open(\"delete.txt\", 'w') as f:\n",
    "                #    f.write(str(self.eyes.map))\n",
    "                attack, x, y= self.eyes.map.isEnemyOnAttackRange()\n",
    "                # if is in attack range\n",
    "                if attack:\n",
    "                    # Move mouse to enemy position\n",
    "                    pydirectinput.moveTo((x+1)*16 + 16, y*16 + 8)\n",
    "                    # attack\n",
    "                    pydirectinput.press('3')\n",
    "                    # Press the left mouse button\n",
    "                    pydirectinput.mouseDown(button='left')\n",
    "                    time.sleep(6)\n",
    "\n",
    "                    # Release the left mouse button\n",
    "                    pydirectinput.mouseUp(button='left')\n",
    "                    reward = 20\n",
    "            elif action == 5: # cut wood\n",
    "                # find closest tree position and check \n",
    "                # if is in cut range\n",
    "                cut, x, y = self.eyes.map.isTreeOnCutRange()\n",
    "                # if is in attack range\n",
    "                if cut:\n",
    "                    # Move mouse to enemy position\n",
    "                    pydirectinput.moveTo((x+1)*16 + 16, y*16 + 8)\n",
    "                    \n",
    "                    # attack\n",
    "                    pydirectinput.press('3')\n",
    "                    # Press the left mouse button\n",
    "                    pydirectinput.mouseDown(button='left')                    \n",
    "                    time.sleep(2)\n",
    "                    # Release the left mouse button\n",
    "                    pydirectinput.mouseUp(button='left')\n",
    "                    reward = 10\n",
    "\n",
    "        done, _ = self.get_done() \n",
    "        observation = self.get_observation()\n",
    "        new_health = self.eyes.map.getHealth()\n",
    "        if new_health - health < 0 or done:\n",
    "            reward = reward - 20\n",
    "        # calculate real reward\n",
    "        info = {}\n",
    "        return observation, reward, done, info\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        time.sleep(10)\n",
    "        pydirectinput.click(x=930, y=512)\n",
    "        self.timer = time.time()\n",
    "        observation = self._get_obs()\n",
    "        return observation\n",
    "        \n",
    "    def render(self):\n",
    "        cv2.imshow('Game', self.current_frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            self.close()\n",
    "         \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    #def _get_obs(self):\n",
    "        #return {\"map\": self.eyes.map.current_map, \"inventory\": self.eyes.inventory.inventory}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\"map\": self.eyes.map.current_map, \"inventory\": self.eyes.inventory.inventory}\n",
    "\n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        self.eyes.updateMap(raw)\n",
    "        self.eyes.updateInventory(raw)\n",
    "        #gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        #resized = cv2.resize(gray, (1920,1080))\n",
    "        #channel = np.reshape(resized, (1,1080,1920))\n",
    "        return {\"map\": self.eyes.map.current_map, \"inventory\": self.eyes.inventory.inventory}\n",
    "    \n",
    "    def get_done(self):\n",
    "        done = False\n",
    "        done_cap = None                   \n",
    "\n",
    "        #elif time.time() - self.timer  > self.time_limit:\n",
    "        #    done = True\n",
    "        done_cap = np.array(self.cap.grab(self.done_location))\n",
    "        done_strings = ['You', 'You ']\n",
    "        res = pytesseract.image_to_string(done_cap)[:4]\n",
    "        if res in done_strings:\n",
    "            done = True\n",
    "        if time.time() - self.day_timer  > self.day_limit:\n",
    "            # reset day\n",
    "\n",
    "            # Open inventory\n",
    "            pydirectinput.press('Esc')\n",
    "            # Click Power menu\n",
    "            pydirectinput.moveTo(50, 315)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click other place in the power menu to reset view\n",
    "            pydirectinput.moveTo(50, 530)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click time menu\n",
    "            pydirectinput.moveTo(50, 630)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click dawn\n",
    "            pydirectinput.moveTo(115, 655)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            \n",
    "            # Close inventory\n",
    "            pydirectinput.press('Esc')\n",
    "\n",
    "            self.day_timer = time.time() \n",
    "        return done, done_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-3-26 Python-3.9.2rc1 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070 Ti, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12319756 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 346 layers, 76157124 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "env = TerrEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#obs=env.get_observation()\n",
    "#env.eyes.updateMap(env.observation)\n",
    "#env.eyes.map.getHealth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done, done_cap = env.get_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(done_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytesseract.image_to_string(done_cap)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for episode in range(10): \n",
    "#    obs = env.reset()\n",
    "#    done = False\n",
    "#    total_reward = 0\n",
    "#    while not done:\n",
    "#        action = env.action_space.sample()\n",
    "#        obs, reward,  done, info =  env.step(env.action_space.sample())\n",
    "#        total_reward  += reward\n",
    "#    print('Total Reward for episode {} is {}'.format(episode, total_reward))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Check Environment    \n",
    "from stable_baselines3.common import env_checker\n",
    "from gym.utils.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_checker.check_env(env)\n",
    "#check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-3-26 Python-3.9.2rc1 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070 Ti, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12319756 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 346 layers, 76157124 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "env = TerrEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x1b9c40ed790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQN('MultiInputPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=1200000, learning_starts=10)\n",
    "model.load('train/best_model_7000') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/DQN_15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 289      |\n",
      "|    ep_rew_mean      | -179     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 0        |\n",
      "|    time_elapsed     | 1648     |\n",
      "|    total_timesteps  | 1155     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.82     |\n",
      "|    n_updates        | 286      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 182      |\n",
      "|    ep_rew_mean      | -79.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 0        |\n",
      "|    time_elapsed     | 2125     |\n",
      "|    total_timesteps  | 1456     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 361      |\n",
      "----------------------------------\n",
      "time for 3000 step: 3534.3905363082886\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "model.learn(total_timesteps=3001, callback =callback)\n",
    "time2 = time.time()\n",
    "print(f'time for 3000 step: {str(time2 - time1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('train_first/best_mode l_50000') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, findOut = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        time.sleep(0.01)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
