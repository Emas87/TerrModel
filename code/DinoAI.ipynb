{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install mss pydirectinput pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "#import gymnasium as gym\n",
    "#from gymnasium import spaces\n",
    "import gym\n",
    "from gym import spaces\n",
    "#from gymnasium.spaces import Box, Discrete\n",
    "from TerrarianEyes import TerrarianEyes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "class TerrEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Setup spaces\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(1,1080,1920), dtype=np.uint8)\n",
    "        self.action_space = spaces.Discrete(8)\n",
    "        # Capture game frames\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top': 0, 'left': 0, 'width': 1920, 'height': 1080}\n",
    "        self.done_location = {'top': 460, 'left': 760, 'width': 400, 'height': 70}\n",
    "        self.action_map = {\n",
    "            0: 'no_op',\n",
    "            1: 'space',\n",
    "            2: 'w', \n",
    "            3: 'd', \n",
    "            4: 'a', \n",
    "            5: 'h', # heal\n",
    "            6: 'attack',\n",
    "            7: 'cut',\n",
    "            #8: 'mine up',\n",
    "            #9: 'mine down',\n",
    "            #10: 'mine left',\n",
    "            #11: 'mine right',\n",
    "            #12: 'attack bow',\n",
    "            #13: 'use torch',\n",
    "            #14: 'use rope',\n",
    "            #15: 'Esc', # open inventory\n",
    "        }\n",
    "        # Create Instance\n",
    "        tiles_weights_path = os.path.join('runs', 'train', 'yolov5s6-tiles', 'weights', 'best.pt')\n",
    "        objects_weights_path = os.path.join('runs', 'train', 'yolov5l6-objects', 'weights', 'best.pt')\n",
    "        self.eyes = TerrarianEyes(tiles_weights_path, objects_weights_path)\n",
    "        self.observation = None\n",
    "        self.timer = None\n",
    "        self.time_limit = 120\n",
    "        self.day_timer = time.time()\n",
    "        self.day_limit = 360\n",
    "           \n",
    "    def step(self, action):\n",
    "        if self.observation is None:\n",
    "            raise AssertionError(\"Cannot call env.step() before calling reset()\")\n",
    "        self.eyes.updateMap(self.observation)\n",
    "        # Get current health\n",
    "        health = self.eyes.map.getHealth()\n",
    "        if action == 0:\n",
    "            reward = 0\n",
    "        elif action < 6:\n",
    "            pydirectinput.press(self.action_map[action])\n",
    "            reward = 1 \n",
    "        else: \n",
    "            self.eyes.updateInventory(self.observation)\n",
    "            # In case we need map or inventory\n",
    "            if action == 6: # attack\n",
    "                # find closest enemy position and check \n",
    "                with open(\"delete.txt\", 'w') as f:\n",
    "                    f.write(str(self.eyes.map))\n",
    "                attack, x, y= self.eyes.map.isEnemyOnAttackRange()\n",
    "                # if is in attack range\n",
    "                if attack:\n",
    "                    # Move mouse to enemy position\n",
    "                    pydirectinput.moveTo((x+1)*16 + 16, y*16 + 8)\n",
    "                    # attack\n",
    "                    pydirectinput.press('1')\n",
    "                    # Press the left mouse button\n",
    "                    pydirectinput.mouseDown(button='left')\n",
    "                    # Release the left mouse button\n",
    "                    pydirectinput.mouseUp(button='left')\n",
    "                    reward = 2\n",
    "                else:\n",
    "                    # if not\n",
    "                    reward = 0\n",
    "            elif action == 7: # cut wood\n",
    "                # find closest tree position and check \n",
    "                # if is in cut range\n",
    "                cut, x, y = self.eyes.map.isTreeOnCutRange()\n",
    "                # if is in attack range\n",
    "                if cut:\n",
    "                    # Move mouse to enemy position\n",
    "                    pydirectinput.moveTo((x+1)*16 + 8, y*16 + 8)\n",
    "                    \n",
    "                    # attack\n",
    "                    pydirectinput.press('3')\n",
    "                    # Press the left mouse button\n",
    "                    pydirectinput.mouseDown(button='left')\n",
    "                    # Release the left mouse button\n",
    "                    pydirectinput.mouseUp(button='left')\n",
    "                    reward = 3\n",
    "                else:\n",
    "                    # if not\n",
    "                    reward = 0\n",
    "\n",
    "            elif action == 8: # mine up FUTURE WORK\n",
    "                # Move mouse above player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 9: # mine down FUTURE WORK\n",
    "                # Move mouse below player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 10: # mine left FUTURE WORK\n",
    "                # Move mouse left to player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 11: # mine right FUTURE WORK\n",
    "                # Move mouse right to player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 12:\n",
    "                # Find bow and use it in closest enemy FUTURE WORK\n",
    "                pydirectinput.press(self.action_map[4])\n",
    "            elif action == 13:\n",
    "                # Find torch and use it FUTURE WORK\n",
    "                pydirectinput.press(self.action_map[5])\n",
    "            elif action == 14:\n",
    "                # Find rope and use it FUTURE WORK\n",
    "                pydirectinput.press(self.action_map[6])\n",
    "\n",
    "        done, _ = self.get_done() \n",
    "        observation = self.get_observation()\n",
    "        self.eyes.updateMap(self.observation)\n",
    "        new_health = self.eyes.map.getHealth()\n",
    "        if new_health - health < 0:\n",
    "            reward = reward - 2\n",
    "        # calculate real reward\n",
    "        info = {}\n",
    "        return observation, reward, done, info\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        time.sleep(10)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        self.timer = time.time()\n",
    "        return self.get_observation()\n",
    "        \n",
    "    def render(self):\n",
    "        cv2.imshow('Game', self.current_frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            self.close()\n",
    "         \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        self.observation = raw\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (1920,1080))\n",
    "        channel = np.reshape(resized, (1,1080,1920))\n",
    "        return channel\n",
    "    \n",
    "    def get_done(self):\n",
    "        done = False\n",
    "        done_cap = None\n",
    "        if time.time() - self.day_timer  > self.day_limit:\n",
    "            # reset day\n",
    "\n",
    "            # Open inventory\n",
    "            pydirectinput.press('Esc')\n",
    "            # Click Power menu\n",
    "            pydirectinput.moveTo(50, 315)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click other place in the power menu to reset view\n",
    "            pydirectinput.moveTo(50, 530)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click time menu\n",
    "            pydirectinput.moveTo(50, 630)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click dawn\n",
    "            pydirectinput.moveTo(115, 655)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            \n",
    "            # Close inventory\n",
    "            pydirectinput.press('Esc')\n",
    "\n",
    "            self.day_timer = time.time()            \n",
    "\n",
    "        elif time.time() - self.timer  > self.time_limit:\n",
    "            done = True\n",
    "        else:\n",
    "            done_cap = np.array(self.cap.grab(self.done_location))\n",
    "            done_strings = ['You', 'You ']\n",
    "            res = pytesseract.image_to_string(done_cap)[:4]\n",
    "            if res in done_strings:\n",
    "                done = True\n",
    "        return done, done_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TerrEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#obs=env.get_observation()\n",
    "#env.eyes.updateMap(env.observation)\n",
    "#env.eyes.map.getHealth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done, done_cap = env.get_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(done_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytesseract.image_to_string(done_cap)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for episode in range(10): \n",
    "#    obs = env.reset()\n",
    "#    done = False\n",
    "#    total_reward = 0\n",
    "#    while not done:\n",
    "#        action = env.action_space.sample()\n",
    "#        obs, reward,  done, info =  env.step(env.action_space.sample())\n",
    "#        total_reward  += reward\n",
    "#    print('Total Reward for episode {} is {}'.format(episode, total_reward))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Check Environment    \n",
    "from stable_baselines3.common import env_checker\n",
    "from gym.utils.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_checker.check_env(env)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TerrEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=12000, learning_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('train_first/best_mode l_50000') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, findOut = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        time.sleep(0.01)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
