{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install mss pydirectinput pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "#from gymnasium import Env\n",
    "#import gymnasium as gym\n",
    "#from gymnasium import spaces\n",
    "import gym\n",
    "from gym import spaces\n",
    "#from gymnasium.spaces import Box, Discrete\n",
    "from TerrarianEyes import TerrarianEyes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "class TerrEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Setup spaces\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(1,1080,1920), dtype=np.uint8)\n",
    "        self.action_space = spaces.Discrete(8)\n",
    "        # Capture game frames\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top': 0, 'left': 0, 'width': 1920, 'height': 1080}\n",
    "        self.done_location = {'top': 460, 'left': 760, 'width': 400, 'height': 70}\n",
    "        self.action_map = {\n",
    "            0: 'no_op',\n",
    "            1: 'space',\n",
    "            2: 'w', \n",
    "            3: 'd', \n",
    "            4: 'a', \n",
    "            5: 'h', # heal\n",
    "            6: 'attack',\n",
    "            7: 'cut',\n",
    "            #8: 'mine up',\n",
    "            #9: 'mine down',\n",
    "            #10: 'mine left',\n",
    "            #11: 'mine right',\n",
    "            #12: 'attack bow',\n",
    "            #13: 'use torch',\n",
    "            #14: 'use rope',\n",
    "            #15: 'Esc', # open inventory\n",
    "        }\n",
    "        # Create Instance\n",
    "        tiles_weights_path = os.path.join('runs', 'train', 'yolov5s6-tiles', 'weights', 'best.pt')\n",
    "        objects_weights_path = os.path.join('runs', 'train', 'yolov5l6-objects', 'weights', 'best.pt')\n",
    "        self.eyes = TerrarianEyes(tiles_weights_path, objects_weights_path)\n",
    "        self.observation = None\n",
    "        self.timer = None\n",
    "        self.time_limit = 120\n",
    "        self.day_timer = time.time()\n",
    "        self.day_limit = 360\n",
    "           \n",
    "    def step(self, action):\n",
    "        if self.observation is None:\n",
    "            raise AssertionError(\"Cannot call env.step() before calling reset()\")\n",
    "        self.eyes.updateMap(self.observation)\n",
    "        # Get current health\n",
    "        health = self.eyes.map.getHealth()\n",
    "        if action == 0:\n",
    "            reward = 0\n",
    "        elif action < 6:\n",
    "            pydirectinput.press(self.action_map[action])\n",
    "            reward = 1 \n",
    "        else: \n",
    "            self.eyes.updateInventory(self.observation)\n",
    "            # In case we need map or inventory\n",
    "            if action == 6: # attack\n",
    "                # find closest enemy position and check \n",
    "                with open(\"delete.txt\", 'w') as f:\n",
    "                    f.write(str(self.eyes.map))\n",
    "                attack, x, y= self.eyes.map.isEnemyOnAttackRange()\n",
    "                # if is in attack range\n",
    "                if attack:\n",
    "                    # Move mouse to enemy position\n",
    "                    pydirectinput.moveTo((x+1)*16 + 16, y*16 + 8)\n",
    "                    # attack\n",
    "                    pydirectinput.press('1')\n",
    "                    # Press the left mouse button\n",
    "                    pydirectinput.mouseDown(button='left')\n",
    "                    # Release the left mouse button\n",
    "                    pydirectinput.mouseUp(button='left')\n",
    "                    reward = 2\n",
    "                else:\n",
    "                    # if not\n",
    "                    reward = 0\n",
    "            elif action == 7: # cut wood\n",
    "                # find closest tree position and check \n",
    "                # if is in cut range\n",
    "                cut, x, y = self.eyes.map.isTreeOnCutRange()\n",
    "                # if is in attack range\n",
    "                if cut:\n",
    "                    # Move mouse to enemy position\n",
    "                    pydirectinput.moveTo((x+1)*16 + 8, y*16 + 8)\n",
    "                    \n",
    "                    # attack\n",
    "                    pydirectinput.press('3')\n",
    "                    # Press the left mouse button\n",
    "                    pydirectinput.mouseDown(button='left')\n",
    "                    # Release the left mouse button\n",
    "                    pydirectinput.mouseUp(button='left')\n",
    "                    reward = 3\n",
    "                else:\n",
    "                    # if not\n",
    "                    reward = 0\n",
    "\n",
    "            elif action == 8: # mine up FUTURE WORK\n",
    "                # Move mouse above player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 9: # mine down FUTURE WORK\n",
    "                # Move mouse below player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 10: # mine left FUTURE WORK\n",
    "                # Move mouse left to player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 11: # mine right FUTURE WORK\n",
    "                # Move mouse right to player position\n",
    "                pydirectinput.press(self.action_map[2])\n",
    "                # Check what was mined\n",
    "                reward = 2\n",
    "            elif action == 12:\n",
    "                # Find bow and use it in closest enemy FUTURE WORK\n",
    "                pydirectinput.press(self.action_map[4])\n",
    "            elif action == 13:\n",
    "                # Find torch and use it FUTURE WORK\n",
    "                pydirectinput.press(self.action_map[5])\n",
    "            elif action == 14:\n",
    "                # Find rope and use it FUTURE WORK\n",
    "                pydirectinput.press(self.action_map[6])\n",
    "\n",
    "        done, _ = self.get_done() \n",
    "        observation = self.get_observation()\n",
    "        self.eyes.updateMap(self.observation)\n",
    "        new_health = self.eyes.map.getHealth()\n",
    "        if new_health - health < 0:\n",
    "            reward = reward - 2\n",
    "        # calculate real reward\n",
    "        info = {}\n",
    "        return observation, reward, done, info\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        time.sleep(10)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        self.timer = time.time()\n",
    "        return self.get_observation()\n",
    "        \n",
    "    def render(self):\n",
    "        cv2.imshow('Game', self.current_frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            self.close()\n",
    "         \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        self.observation = raw\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (1920,1080))\n",
    "        channel = np.reshape(resized, (1,1080,1920))\n",
    "        return channel\n",
    "    \n",
    "    def get_done(self):\n",
    "        done = False\n",
    "        done_cap = None\n",
    "        if time.time() - self.day_timer  > self.day_limit:\n",
    "            # reset day\n",
    "\n",
    "            # Open inventory\n",
    "            pydirectinput.press('Esc')\n",
    "            # Click Power menu\n",
    "            pydirectinput.moveTo(50, 315)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click other place in the power menu to reset view\n",
    "            pydirectinput.moveTo(50, 530)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click time menu\n",
    "            pydirectinput.moveTo(50, 630)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            #Click dawn\n",
    "            pydirectinput.moveTo(115, 655)\n",
    "            # Press the left mouse button\n",
    "            pydirectinput.mouseDown(button='left')\n",
    "            # Release the left mouse button\n",
    "            pydirectinput.mouseUp(button='left')\n",
    "\n",
    "            \n",
    "            # Close inventory\n",
    "            pydirectinput.press('Esc')\n",
    "\n",
    "            self.day_timer = time.time()            \n",
    "\n",
    "        elif time.time() - self.timer  > self.time_limit:\n",
    "            done = True\n",
    "        else:\n",
    "            done_cap = np.array(self.cap.grab(self.done_location))\n",
    "            done_strings = ['You', 'You ']\n",
    "            res = pytesseract.image_to_string(done_cap)[:4]\n",
    "            if res in done_strings:\n",
    "                done = True\n",
    "        return done, done_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-3-26 Python-3.9.2rc1 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070 Ti, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12319756 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 346 layers, 76157124 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "env = TerrEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#obs=env.get_observation()\n",
    "#env.eyes.updateMap(env.observation)\n",
    "#env.eyes.map.getHealth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done, done_cap = env.get_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(done_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytesseract.image_to_string(done_cap)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for episode in range(10): \n",
    "#    obs = env.reset()\n",
    "#    done = False\n",
    "#    total_reward = 0\n",
    "#    while not done:\n",
    "#        action = env.action_space.sample()\n",
    "#        obs, reward,  done, info =  env.step(env.action_space.sample())\n",
    "#        total_reward  += reward\n",
    "#    print('Total Reward for episode {} is {}'.format(episode, total_reward))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Check Environment    \n",
    "from stable_baselines3.common import env_checker\n",
    "from gym.utils.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_checker.check_env(env)\n",
    "#check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-3-26 Python-3.9.2rc1 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070 Ti, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12319756 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 346 layers, 76157124 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "env = TerrEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.78 GiB (GPU 0; 8.00 GiB total capacity; 4.79 GiB already allocated; 654.98 MiB free; 4.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m DQN(\u001b[39m'\u001b[39;49m\u001b[39mCnnPolicy\u001b[39;49m\u001b[39m'\u001b[39;49m, env, tensorboard_log\u001b[39m=\u001b[39;49mLOG_DIR, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, buffer_size\u001b[39m=\u001b[39;49m\u001b[39m12000\u001b[39;49m, learning_starts\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:140\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_net_target: th\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_model()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:143\u001b[0m, in \u001b[0;36mDQN._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_model\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_model()\n\u001b[0;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_aliases()\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Copy running stats, see GH issue #996\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:204\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer_class(\n\u001b[0;32m    189\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_size,\n\u001b[0;32m    190\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mreplay_buffer_kwargs,  \u001b[39m# pytype:disable=wrong-keyword-args\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     )\n\u001b[0;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_class(  \u001b[39m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space,\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space,\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_schedule,\n\u001b[0;32m    202\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_kwargs,  \u001b[39m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[0;32m    203\u001b[0m )\n\u001b[1;32m--> 204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    206\u001b[0m \u001b[39m# Convert train freq parameter to TrainFreq object\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_freq()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 641 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.78 GiB (GPU 0; 8.00 GiB total capacity; 4.79 GiB already allocated; 654.98 MiB free; 4.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=12000, learning_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('train_first/best_mode l_50000') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, findOut = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        time.sleep(0.01)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
